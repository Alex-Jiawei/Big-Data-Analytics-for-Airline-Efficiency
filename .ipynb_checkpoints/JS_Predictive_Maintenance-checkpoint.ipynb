{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17ba1cf-5f3d-4441-8155-3ce2bd57fbc1",
   "metadata": {},
   "source": [
    "# Machine Learning Predictive Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6ad93d-a4cc-45c9-8a6a-0aa8caa3af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder,  MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c3a3a-a9c0-4543-a1c9-fe777aa841a0",
   "metadata": {},
   "source": [
    "Jean-Sebastien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7240b4ee-9de8-4e31-917d-b0a0f5b2e2f2",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d2c005-b0cc-44c3-9424-3db8bd509068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "datapath_18 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2018.csv\"\n",
    "df_18 = spark.read.csv(datapath_18, header=True, inferSchema=True)\n",
    "datapath_19 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2019.csv\"\n",
    "df_19 = spark.read.csv(datapath_19, header=True, inferSchema=True)\n",
    "datapath_20 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2020.csv\"\n",
    "df_20 = spark.read.csv(datapath_20, header=True, inferSchema=True)\n",
    "datapath_21 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2021.csv\"\n",
    "df_21 = spark.read.csv(datapath_21, header=True, inferSchema=True)\n",
    "datapath_22 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2022.csv\"\n",
    "df_22 = spark.read.csv(datapath_22, header=True, inferSchema=True)\n",
    "datapath_air = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Airlines.csv\"\n",
    "df_airlines = spark.read.csv(datapath_air, header=True, inferSchema=True)\n",
    "df_all = df_18.union(df_19).union(df_20).union(df_21).union(df_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebccba-a5bf-4b5f-b1cd-a14568b27a6b",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce5362e1-87f7-4304-ab3c-426de3e560c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+---------+---------------+---------------+------------------+----------------------+\n",
      "|Tail_Number|ActualElapsedTime|Cancelled|DepDelayMinutes|ArrDelayMinutes|       FlightHours|HoursBeforeMaintenance|\n",
      "+-----------+-----------------+---------+---------------+---------------+------------------+----------------------+\n",
      "|      219NV|            161.0|    false|            0.0|            0.0| 2.683333333333333|                 200.0|\n",
      "|      219NV|            181.0|    false|            0.0|            9.0|3.0166666666666666|                 200.0|\n",
      "|      219NV|            135.0|    false|            0.0|            0.0|              2.25|                 200.0|\n",
      "|      219NV|            132.0|    false|            0.0|            3.0|               2.2|                 200.0|\n",
      "|      219NV|            124.0|    false|            0.0|            4.0| 2.066666666666667|                 200.0|\n",
      "|      219NV|            124.0|    false|            4.0|           10.0| 2.066666666666667|                 200.0|\n",
      "|      219NV|            161.0|    false|           10.0|            0.0| 2.683333333333333|                 200.0|\n",
      "|      219NV|            164.0|    false|            0.0|            0.0|2.7333333333333334|                 200.0|\n",
      "|      219NV|            141.0|    false|            0.0|            0.0|              2.35|                 200.0|\n",
      "|      219NV|            125.0|    false|           10.0|            4.0|2.0833333333333335|                 200.0|\n",
      "+-----------+-----------------+---------+---------------+---------------+------------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flight_hours_threshold_low = 400\n",
    "flight_hours_threshold_high = 600\n",
    "maintenance_interval_low = 200\n",
    "maintenance_interval_high = 300\n",
    "\n",
    "selected_columns = ['FlightDate','Tail_Number', 'ActualElapsedTime', 'DepDelayMinutes', 'ArrDelayMinutes', 'AirTime', 'Distance', 'DepDel15', 'TaxiOut', 'TaxiIn', 'CRSArrTime', 'Cancelled']\n",
    "df = df_all.select(selected_columns)\n",
    "df = df.na.drop()\n",
    "df = df.withColumn('DepDel15', df['DepDel15'].cast('int'))\n",
    "df = df.withColumn('LateArrival', (df['ArrDelayMinutes'] > 15).cast('int'))\n",
    "df = df.withColumn('Tail_Number', F.when(df['Tail_Number'].isNull(), 'Unknown').otherwise(df['Tail_Number']))\n",
    "\n",
    "string_indexer = StringIndexer(inputCol='Tail_Number', outputCol='Tail_Number_Index')\n",
    "df = string_indexer.fit(df).transform(df)\n",
    "\n",
    "df = df.withColumn('FlightHours', col('ActualElapsedTime') / 60.0) \n",
    "window_spec = Window().partitionBy('Tail_Number').orderBy('FlightDate')\n",
    "df = df.withColumn('CumulativeFlightHours', F.sum('FlightHours').over(window_spec))\n",
    "\n",
    "\n",
    "df = df.withColumn(\n",
    "    'AdjustedMaintenanceInterval',\n",
    "    F.when(df['Cancelled'] == 1, 0).otherwise(\n",
    "        F.when(df['DepDelayMinutes'] > 0, df['CumulativeFlightHours'] % maintenance_interval_low).otherwise(\n",
    "            df['CumulativeFlightHours'] % maintenance_interval_high\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a variable representing the number of hours before the next maintenance\n",
    "df = df.withColumn(\n",
    "    'HoursBeforeMaintenance',\n",
    "    F.when(\n",
    "        ((df['CumulativeFlightHours'] + df['FlightHours'] >= flight_hours_threshold_low) & (df['CumulativeFlightHours'] + df['FlightHours'] <= flight_hours_threshold_high)) |\n",
    "        (df['AdjustedMaintenanceInterval'] == 0),\n",
    "        0\n",
    "    ).otherwise(\n",
    "        F.when(df['AdjustedMaintenanceInterval'] < maintenance_interval_low, maintenance_interval_low).otherwise(df['AdjustedMaintenanceInterval'])\n",
    "    )\n",
    ")\n",
    "\n",
    "df = df.withColumn('TotalTaxiTime', df['TaxiOut'] + df['TaxiIn'])\n",
    "df = df.withColumn('ScheduledArrivalDelay', df['CRSArrTime'] - (df['DepDelayMinutes'] + df['AirTime']))\n",
    "df = df.withColumn('DistancePerMinute', df['Distance'] / (df['AirTime'] + 1))\n",
    "\n",
    "df.select('Tail_Number', 'ActualElapsedTime', 'Cancelled', 'DepDelayMinutes', 'ArrDelayMinutes', 'FlightHours', 'HoursBeforeMaintenance').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f3b14-01e3-4d77-8a7c-4d9ad71fbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['DepDelayMinutes', 'ArrDelayMinutes', 'TotalTaxiTime', 'ScheduledArrivalDelay', 'DistancePerMinute', 'Tail_Number_Index', 'CumulativeFlightHours', 'FlightHours', 'AdjustedMaintenanceInterval', 'HoursBeforeMaintenance']\n",
    "categorical_columns = ['DepDel15', 'Cancelled']\n",
    "assembler_numerical = VectorAssembler(inputCols=numerical_columns, outputCol='numerical_features')\n",
    "scaler = MinMaxScaler(inputCol='numerical_features', outputCol='scaled_numerical_features')\n",
    "encoders = [OneHotEncoder(inputCol=col, outputCol=f'{col}_encoded') for col in categorical_columns]\n",
    "assembler_all = VectorAssembler(\n",
    "    inputCols=[f'{col}_encoded' for col in categorical_columns] + ['scaled_numerical_features', 'HoursBeforeMaintenance'],\n",
    "    outputCol='features'\n",
    ")\n",
    "pipeline = Pipeline(stages=[assembler_numerical, scaler] + encoders + [assembler_all])\n",
    "df = df.withColumn('Cancelled', col('Cancelled').cast('int'))\n",
    "transformed_df = pipeline.fit(df).transform(df)\n",
    "transformed_df = transformed_df.select(['features', 'HoursBeforeMaintenance'])\n",
    "transformed_df.printSchema()\n",
    "transformed_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d17780-0178-46f7-b697-1324c71848c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = transformed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "lr = LinearRegression(labelCol='HoursBeforeMaintenance', featuresCol='features', maxIter=10)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=RegressionEvaluator(labelCol='HoursBeforeMaintenance'),\n",
    "                          numFolds=3)\n",
    "\n",
    "pipeline = Pipeline(stages=[crossval])\n",
    "\n",
    "model = pipeline.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='HoursBeforeMaintenance', metricName='rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e54432-106c-4eca-b79e-26532cc41c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select('HoursBeforeMaintenance', 'prediction').show(40)\n",
    "predictions.withColumn('PredictionError', col('prediction') - col('HoursBeforeMaintenance')).select('HoursBeforeMaintenance', 'prediction', 'PredictionError').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8859a-5ca7-4f0d-b2d8-fed3950895c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_150_hours = predictions.filter((predictions['HoursBeforeMaintenance'] >= 100) & (predictions['HoursBeforeMaintenance'] <= 155))\n",
    "flights_with_150_hours.select('HoursBeforeMaintenance', 'prediction').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b834e-1141-4a5e-96f5-25270fd437fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_predictions = predictions.filter((predictions['HoursBeforeMaintenance'] != 0) & (predictions['HoursBeforeMaintenance'] != 200))\n",
    "count_filtered_predictions = filtered_predictions.count()\n",
    "\n",
    "# Show the count\n",
    "print(f\"Number of predictions where HoursBeforeMaintenance is not 0 or 200: {count_filtered_predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba687005-28b8-4ca1-b50e-eb13bd100107",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_predictions = predictions.filter((predictions['HoursBeforeMaintenance'] != 0) & (predictions['HoursBeforeMaintenance'] != 200))\n",
    "filtered_values_list = filtered_predictions.select('HoursBeforeMaintenance', 'prediction').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea1051-7bef-42d3-90da-9b6280f3be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_values_list[0]['HoursBeforeMaintenance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96625fba-85f6-497a-b570-439f15243257",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835386b-63b4-4bb6-9cda-2cfa3a9d5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='prediction', y='HoursBeforeMaintenance - prediction', data=predictions)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Hours Before Maintenance')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e242545-f4b5-45ab-a136-08688c57cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='HoursBeforeMaintenance', y='prediction', data=predictions[(predictions['HoursBeforeMaintenance'] != 0) & (predictions['HoursBeforeMaintenance'] != 200)])\n",
    "plt.title('Actual vs. Predicted Hours Before Maintenance')\n",
    "plt.xlabel('Actual Hours Before Maintenance')\n",
    "plt.ylabel('Predicted Hours Before Maintenance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9e0f9-e171-4ddf-8cf1-78731b759bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(model.bestModel, 'featureImportances'):\n",
    "    feature_importance = model.bestModel.featureImportances.toArray()\n",
    "    features = [col for col in transformed_df.columns if col != 'HoursBeforeMaintenance']\n",
    "    importance_dict = dict(zip(features, feature_importance))\n",
    "\n",
    "    sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    feature_names, importances = zip(*sorted_importance)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=importances, y=feature_names)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6794a6-2575-48b2-8f66-b1c801529dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
