{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17ba1cf-5f3d-4441-8155-3ce2bd57fbc1",
   "metadata": {},
   "source": [
    "# Machine Learning Predictive Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa6ad93d-a4cc-45c9-8a6a-0aa8caa3af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder,  MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c3a3a-a9c0-4543-a1c9-fe777aa841a0",
   "metadata": {},
   "source": [
    "Jean-Sebastien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7240b4ee-9de8-4e31-917d-b0a0f5b2e2f2",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d2c005-b0cc-44c3-9424-3db8bd509068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "datapath_18 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2018.csv\"\n",
    "df_18 = spark.read.csv(datapath_18, header=True, inferSchema=True)\n",
    "datapath_19 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2019.csv\"\n",
    "df_19 = spark.read.csv(datapath_19, header=True, inferSchema=True)\n",
    "datapath_20 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2020.csv\"\n",
    "df_20 = spark.read.csv(datapath_20, header=True, inferSchema=True)\n",
    "datapath_21 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2021.csv\"\n",
    "df_21 = spark.read.csv(datapath_21, header=True, inferSchema=True)\n",
    "datapath_22 = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Combined_Flights_2022.csv\"\n",
    "df_22 = spark.read.csv(datapath_22, header=True, inferSchema=True)\n",
    "datapath_air = \"gs://msca-bdp-student-gcs/Group4_Final_Project/archive/Airlines.csv\"\n",
    "df_airlines = spark.read.csv(datapath_air, header=True, inferSchema=True)\n",
    "df_all = df_18.union(df_19).union(df_20).union(df_21).union(df_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d93cfa-5a3d-4783-b7a8-720b8a3caf4e",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebccba-a5bf-4b5f-b1cd-a14568b27a6b",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce5362e1-87f7-4304-ab3c-426de3e560c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------------+---------+---------------+---------------+----------------------+\n",
      "|Tail_Number|FlightDate|ActualElapsedTime|Cancelled|DepDelayMinutes|ArrDelayMinutes|HoursBeforeMaintenance|\n",
      "+-----------+----------+-----------------+---------+---------------+---------------+----------------------+\n",
      "|      219NV|2018-01-01|            161.0|    false|            0.0|            0.0|                 200.0|\n",
      "|      219NV|2018-01-01|            181.0|    false|            0.0|            9.0|                 200.0|\n",
      "|      219NV|2018-01-01|            135.0|    false|            0.0|            0.0|                 200.0|\n",
      "|      219NV|2018-01-01|            132.0|    false|            0.0|            3.0|                 200.0|\n",
      "|      219NV|2018-01-02|            124.0|    false|            0.0|            4.0|                 200.0|\n",
      "|      219NV|2018-01-02|            124.0|    false|            4.0|           10.0|                 200.0|\n",
      "|      219NV|2018-01-02|            161.0|    false|           10.0|            0.0|                 200.0|\n",
      "|      219NV|2018-01-02|            164.0|    false|            0.0|            0.0|                 200.0|\n",
      "|      219NV|2018-01-02|            141.0|    false|            0.0|            0.0|                 200.0|\n",
      "|      219NV|2018-01-03|            125.0|    false|           10.0|            4.0|                 200.0|\n",
      "+-----------+----------+-----------------+---------+---------------+---------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flight_hours_threshold_low = 400\n",
    "flight_hours_threshold_high = 600\n",
    "maintenance_interval_low = 200\n",
    "maintenance_interval_high = 300\n",
    "selected_columns = ['FlightDate','Tail_Number','ActualElapsedTime', 'DepDelayMinutes', 'ArrDelayMinutes', 'AirTime', 'Distance', 'DepDel15', 'TaxiOut', 'TaxiIn', 'CRSArrTime', 'Cancelled']\n",
    "df = df_all.select(selected_columns)\n",
    "df = df.na.drop()\n",
    "df = df.withColumn('DepDel15', df['DepDel15'].cast('int'))\n",
    "df = df.withColumn('LateArrival', (df['ArrDelayMinutes'] > 15).cast('int'))\n",
    "df = df.withColumn('Tail_Number', F.when(df['Tail_Number'].isNull(), 'Unknown').otherwise(df['Tail_Number']))\n",
    "string_indexer = StringIndexer(inputCol='Tail_Number', outputCol='Tail_Number_Index')\n",
    "df = string_indexer.fit(df).transform(df)\n",
    "df = df.withColumn('FlightHours', col('ActualElapsedTime') / 60.0) \n",
    "window_spec = Window().partitionBy('Tail_Number').orderBy('FlightDate')\n",
    "df = df.withColumn('CumulativeFlightHours', sum('FlightHours').over(window_spec))\n",
    "df = df.withColumn(\n",
    "    'AdjustedMaintenanceInterval',\n",
    "    when(df['Cancelled'] == 1, 0).otherwise(\n",
    "        when(df['DepDelayMinutes'] > 0, df['CumulativeFlightHours'] % maintenance_interval_low).otherwise(\n",
    "            df['CumulativeFlightHours'] % maintenance_interval_high\n",
    "        )\n",
    "    )\n",
    ")\n",
    "df = df.withColumn(\n",
    "    'HoursBeforeMaintenance',\n",
    "    when(\n",
    "        ((df['CumulativeFlightHours'] + df['FlightHours'] >= flight_hours_threshold_low) & (df['CumulativeFlightHours'] + df['FlightHours'] <= flight_hours_threshold_high)) |\n",
    "        (df['AdjustedMaintenanceInterval'] == 0),\n",
    "        0\n",
    "    ).otherwise(\n",
    "        when(df['AdjustedMaintenanceInterval'] < maintenance_interval_low, maintenance_interval_low).otherwise(df['AdjustedMaintenanceInterval'])\n",
    "    )\n",
    ")\n",
    "df = df.withColumn('TotalTaxiTime', df['TaxiOut'] + df['TaxiIn'])\n",
    "df = df.withColumn('ScheduledArrivalDelay', df['CRSArrTime'] - (df['DepDelayMinutes'] + df['AirTime']))\n",
    "df = df.withColumn('DistancePerMinute', df['Distance'] / (df['AirTime'] + 1))  # Adding 1 to avoid division by zero\n",
    "df.select('Tail_Number', 'FlightDate', 'ActualElapsedTime', 'Cancelled', 'DepDelayMinutes', 'ArrDelayMinutes', 'HoursBeforeMaintenance').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de2f3b14-01e3-4d77-8a7c-4d9ad71fbc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- HoursBeforeMaintenance: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|            features|HoursBeforeMaintenance|\n",
      "+--------------------+----------------------+\n",
      "|[1.0,0.0,0.0,0.08...|                 200.0|\n",
      "|[1.0,0.0,0.001244...|                 200.0|\n",
      "|[1.0,0.0,0.0,0.03...|                 200.0|\n",
      "|[1.0,0.0,4.148230...|                 200.0|\n",
      "|[1.0,0.0,5.530973...|                 200.0|\n",
      "+--------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "numerical_columns = ['DepDelayMinutes', 'ArrDelayMinutes', 'TotalTaxiTime', 'ScheduledArrivalDelay', 'DistancePerMinute', 'Tail_Number_Index', 'CumulativeFlightHours', 'FlightHours', 'AdjustedMaintenanceInterval', 'HoursBeforeMaintenance']\n",
    "categorical_columns = ['DepDel15', 'Cancelled']\n",
    "assembler_numerical = VectorAssembler(inputCols=numerical_columns, outputCol='numerical_features')\n",
    "scaler = MinMaxScaler(inputCol='numerical_features', outputCol='scaled_numerical_features')\n",
    "encoders = [OneHotEncoder(inputCol=col, outputCol=f'{col}_encoded') for col in categorical_columns]\n",
    "assembler_all = VectorAssembler(\n",
    "    inputCols=[f'{col}_encoded' for col in categorical_columns] + ['scaled_numerical_features', 'HoursBeforeMaintenance'],\n",
    "    outputCol='features'\n",
    ")\n",
    "pipeline = Pipeline(stages=[assembler_numerical, scaler] + encoders + [assembler_all])\n",
    "df = df.withColumn('Cancelled', col('Cancelled').cast('int'))\n",
    "transformed_df = pipeline.fit(df).transform(df)\n",
    "transformed_df = transformed_df.select(['features', 'HoursBeforeMaintenance'])\n",
    "transformed_df.printSchema()\n",
    "transformed_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d17780-0178-46f7-b697-1324c71848c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data, test_data = transformed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "lr = LinearRegression(labelCol='HoursBeforeMaintenance', featuresCol='features', maxIter=10)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=RegressionEvaluator(labelCol='HoursBeforeMaintenance'),\n",
    "                          numFolds=3)\n",
    "\n",
    "pipeline = Pipeline(stages=[crossval])\n",
    "\n",
    "model = pipeline.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='HoursBeforeMaintenance', metricName='rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
